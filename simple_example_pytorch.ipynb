{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from ppnp.pytorch import PPNP\n",
    "from ppnp.pytorch.training import train_model\n",
    "from ppnp.pytorch.earlystopping import stopping_args\n",
    "from ppnp.pytorch.propagation import PPRExact, PPRPowerIteration\n",
    "from ppnp.data.io import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        format='%(asctime)s: %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "\n",
    "First we need to load the dataset we want to train on. The datasets used are in the `SparseGraph` format. This is just a class providing the adjacency, attribute and label matrices in a dense (`np.ndarray`) or sparse (`scipy.sparse.csr_matrix`) matrix format and some (in principle unnecessary) convenience functions. If you want to use external datasets, you can e.g. use the `networkx_to_sparsegraph` method in `ppnp.data.io` for converting NetworkX graphs to our SparseGraph format.\n",
    "\n",
    "The four datasets from the paper (Cora-ML, Citeseer, PubMed and MS Academic) can be found in the directory `data`.\n",
    "\n",
    "For this example we choose the Cora-ML graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjohnson/projects/ppnp/ppnp/data/sparsegraph.py:393: UserWarning: 124 self loops removed\n",
      "  warnings.warn(\"{0} self loops removed\".format(num_self_loops))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Undirected, unweighted and connected SparseGraph with 7336 edges (no self-loops). Data: adj_matrix (2110x2110), attr_matrix (2110x3703), labels (2110), node_names (2110), class_names (6)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_name = 'citeseer'\n",
    "graph = load_dataset(graph_name)\n",
    "graph.standardize(select_lcc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up propagation\n",
    "\n",
    "Next we need to set up the proper propagation scheme. In the paper we've introduced the exact PPR propagation used in PPNP and the PPR power iteration propagation used in APPNP.\n",
    "\n",
    "Here we use the hyperparameters from the paper. Note that we should use a different `alpha = 0.2` for MS Academic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_ppnp = PPRExact(graph.adj_matrix, alpha=0.1)\n",
    "prop_appnp = PPRPowerIteration(graph.adj_matrix, alpha=0.1, niter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose model hyperparameters\n",
    "\n",
    "Now we choose the hyperparameters. These are the ones used in the paper for all datasets.\n",
    "\n",
    "Note that we choose the propagation for APPNP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'hiddenunits': [64],\n",
    "    'drop_prob': 0.5,\n",
    "    'propagation': prop_appnp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "Now we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_split_args = {'ntrain_per_class': 20, 'nstopping': 500, 'nknown': 1500, 'seed': 2413340114}\n",
    "reg_lambda = 5e-3\n",
    "learning_rate = 0.01\n",
    "\n",
    "test = True\n",
    "device = 'cuda'\n",
    "print_interval = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stopping_acc': 0.744, 'valtest_acc': 0.760655737704918, 'test': True}\n",
      "{'stopping_acc': 0.738, 'valtest_acc': 0.7262295081967213, 'test': True}\n",
      "{'stopping_acc': 0.75, 'valtest_acc': 0.740983606557377, 'test': True}\n",
      "{'stopping_acc': 0.742, 'valtest_acc': 0.740983606557377, 'test': True}\n",
      "{'stopping_acc': 0.738, 'valtest_acc': 0.7377049180327869, 'test': True}\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(train_model(\n",
    "            PPNP, graph, model_args, learning_rate, reg_lambda,\n",
    "            idx_split_args, stopping_args, test, None))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
